---
layout: post
section-type: post
title: Model Blog&#x3a; David Robinson of Variance Explained
category: Blogging
tags: [ ]
---

<p style="text-align: center"><a href="http://varianceexplained.org/">http://varianceexplained.org/</a></p>

Now this bit of spotlight is long overdue - [_Variance Explained_](http://varianceexplained.org/) was my first "model blog" in spirit, if not in post [chronology](/categories/blogging).

[David Robinson](http://varianceexplained.org/about/) is so good at blogging. I was recently reminded of this while reading his latest post, ["What's the difference between data science, machine learning, and artificial intelligence?"](http://varianceexplained.org/r/ds-ml-ai/) [^brief-thoughts].

His writing is engaging and plain-speaking, and he has a friendly style.

I greatly admire the look and feel of his blog - so much so that I've tried replicating his â€Žclean way of referencing, linking, and footnoting within posts. His use of these keeps posts streamlined and highly readable.

I even chose to use [Jekyll](https://jekyllrb.com/) as the static site generator for this blog after noticing it in his footer.

I analyzed and reproduced (swapping Python for R) [one of his posts](/portfolio-building/2017/10/18/data-is-all-around-us) as one of my very first in-depth undertakings for this blog. It introduced me to the concept of [tidy data](http://vita.had.co.nz/papers/tidy-data.html) and much more. Other posts I'd recommend:
1. ["Text analysis of Trump's tweets confirms he writes only the (angrier) Android half"](http://varianceexplained.org/r/trump-tweets/) (and its [follow-up a year later](http://varianceexplained.org/r/trump-followup/))
2. ["Don't teach built-in plotting to beginners (teach ggplot2)"](http://varianceexplained.org/r/teach_ggplot2_to_beginners/) [^source]
3. ["Two years as a Data Scientist at Stack Overflow"](http://varianceexplained.org/r/two-years-data-scientist/)
4. ["Advice to aspiring data scientists: start a blog"](http://varianceexplained.org/r/start-blog/) (sound [familiar](/blogging/2017/07/09/fast-ai-blog)?)
5. ["Teach the tidyverse to beginners"](http://varianceexplained.org/r/teach-tidyverse/)

I only discovered _Variance Explained_ this past May, but the rest of his [backlog](http://varianceexplained.org/posts/) looks just as impressive[^mixture-models].

I am a huge fan and grateful to have David's continued example.

#### Footnotes

[^brief-thoughts]: True to style, it's an awesome post. "Data science produces insights. Machine learning produces predictions. Artificial intelligence produces actions." - _oversimplification_ made useful, then followed by a breakdown of what he means by it. I also enjoyed his use of Twitter snark from the community. And the [AI effect](https://en.wikipedia.org/wiki/AI_effect) has its own Wikipedia page!
[^source]: This post was actually brought to my attention during the Johns Hopkins [_R Programming_](https://www.coursera.org/learn/r-programming/home/welcome) course that I took back in 2016.
[^mixture-models]: For example, ["Understanding mixture models and expectation-maximization (using baseball statistics)"](http://varianceexplained.org/r/mixture-models-baseball/) sounds like it could help reinforce some of the stuff I learned about [topic models](/notes/2017/12/07/topics-and-dim-reduction) and Latent Dirichlet Allocation.
